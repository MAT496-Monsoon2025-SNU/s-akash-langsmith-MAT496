{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Tracing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain and LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import operator\n",
    "from langchain.schema import Document\n",
    "from langchain_core.messages import HumanMessage, AnyMessage, get_buffer_string\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from utils import get_vector_db_retriever, RAG_PROMPT\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "retriever = get_vector_db_retriever()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define Graph state\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    messages: Annotated[List[AnyMessage], operator.add]\n",
    "    documents: List[Document]\n",
    "\n",
    "# Define Nodes\n",
    "def retrieve_documents(state: GraphState):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(f\"{get_buffer_string(messages)} {question}\")\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "def generate_response(state: GraphState):\n",
    "    question = state[\"question\"]\n",
    "    messages = state[\"messages\"]\n",
    "    documents = state[\"documents\"]\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    \n",
    "    rag_prompt_formatted = RAG_PROMPT.format(context=formatted_docs, conversation=messages, question=question)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "    return {\"documents\": documents, \"messages\": [HumanMessage(question), generation]}\n",
    "\n",
    "# Define Graph\n",
    "graph_builder = StateGraph(GraphState)\n",
    "graph_builder.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "graph_builder.add_node(\"generate_response\", generate_response)\n",
    "graph_builder.add_edge(START, \"retrieve_documents\")\n",
    "graph_builder.add_edge(\"retrieve_documents\", \"generate_response\")\n",
    "graph_builder.add_edge(\"generate_response\", END)\n",
    "\n",
    "simple_rag_graph = graph_builder.compile()\n",
    "display(Image(simple_rag_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Why should I use tracing in LangChain?',\n",
       " 'messages': [HumanMessage(content='Why should I use tracing in LangChain?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Using tracing in LangChain allows for better observability and evaluation of agentic workflows, helping you understand the performance and behavior of your applications. It enables you to log custom LLM traces, which can provide insights into token usage and cost calculations. Additionally, tracing helps in troubleshooting and optimizing your applications by visualizing the flow of data across services.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 1370, 'total_tokens': 1439, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CN01Ut6Rs37Q7VdzWQUrwwwXo2pOj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6091a6e2-116f-4c72-bcad-2606e7205782-0', usage_metadata={'input_tokens': 1370, 'output_tokens': 69, 'total_tokens': 1439, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'documents': [Document(metadata={'id': '10df43f5-d77b-420b-ac72-08e2d78cc784', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_opentelemetry', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_opentelemetry'}, page_content='Set up distributed tracing with LangChain\\u200b\\nTo enable distributed tracing across multiple services:'),\n",
       "  Document(metadata={'id': '86649ca8-4c18-4886-946d-da118cf6c671', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph'}, page_content='Trace with LangGraph - Docs by LangChainSkip to main contentOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewConceptsTutorial - Trace a RAG applicationTracing setupIntegrationsOverviewLangChainLangGraphAnthropic (Python only)OpenAIAutoGenClaude CodeCrewAIGoogle ADKInstructor (Python only)OpenAI Agents SDKOpenTelemetrySemantic KernelVercel AI SDKManual instrumentationConfiguration & troubleshootingProject & environment settingsAdvanced tracing techniquesData & privacyTroubleshooting guidesViewing & managing tracesFilter tracesQuery traces (SDK)Compare tracesShare or unshare a trace publiclyView server logs for a traceBulk export trace dataAutomationsSet up automation rulesConfigure webhook notifications for rulesFeedback & evaluationLog user feedback using the SDKSet up online evaluatorsMonitoring & alertingMonitor projects with dashboardsAlertsConfigure webhook notifications for alertsInsights (Beta)Data type referenceRun (span) data formatFeedback data formatTrace query syntaxOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationIntegrationsTrace with LangGraphGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumOn this pageWith LangChain1. Installation2. Configure your environment3. Log a traceWithout LangChain1. Installation2. Configure your environment3. Log a traceTracing setupIntegrationsTrace with LangGraphCopy pageCopy pageLangSmith smoothly integrates with LangGraph (Python and JS) to help you trace agentic workflows, whether you’re using LangChain modules or other SDKs.\\n\\u200bWith LangChain\\nIf you are using LangChain modules within LangGraph, you only need to set a few environment variables to enable tracing.\\nThis guide will walk through a basic example. For more detailed information on configuration, see the Trace With LangChain guide.\\n\\u200b1. Installation'),\n",
       "  Document(metadata={'id': 'bd556e9f-83e5-4679-9c7f-ec21856f0fd5', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides/log_llm_trace', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides/log_llm_trace'}, page_content='Log custom LLM traces - Docs by LangChainSkip to main contentOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewConceptsTutorial - Trace a RAG applicationTracing setupIntegrationsManual instrumentationCustom instrumentationTrace with APILog custom LLM tracesLog retriever tracesConfiguration & troubleshootingProject & environment settingsAdvanced tracing techniquesData & privacyTroubleshooting guidesViewing & managing tracesFilter tracesQuery traces (SDK)Compare tracesShare or unshare a trace publiclyView server logs for a traceBulk export trace dataAutomationsSet up automation rulesConfigure webhook notifications for rulesFeedback & evaluationLog user feedback using the SDKSet up online evaluatorsMonitoring & alertingMonitor projects with dashboardsAlertsConfigure webhook notifications for alertsInsights (Beta)Data type referenceRun (span) data formatFeedback data formatTrace query syntaxOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationManual instrumentationLog custom LLM tracesGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumOn this pageChat-style modelsUsing LangChain OSS or LangSmith wrappersImplementing your own custom chat-modelProvide token and cost informationSetting run metadataSetting run outputsTime-to-first-tokenInstruct-style modelsTracing setupManual instrumentationLog custom LLM tracesCopy pageCopy pageNothing will break if you don’t log LLM traces in the correct format - data will still be logged. However, the data will not be processed or rendered in a way that is specific to LLMs.\\nLangSmith provides special rendering and processing for LLM traces, including token counting (assuming token counts are not available from the model provider) and token-based cost calculation. In order to make the most of this feature, you must log your LLM traces in a specific format.'),\n",
       "  Document(metadata={'id': 'fd520f9d-ef4e-4d77-8d03-2cb17254f079', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/observability/how_to_guides', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/observability/how_to_guides'}, page_content='Trace with LangChain (Python and JS/TS) - Docs by LangChainSkip to main contentOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewConceptsTutorial - Trace a RAG applicationTracing setupIntegrationsOverviewLangChainLangGraphAnthropic (Python only)OpenAIAutoGenClaude CodeCrewAIGoogle ADKInstructor (Python only)OpenAI Agents SDKOpenTelemetrySemantic KernelVercel AI SDKManual instrumentationConfiguration & troubleshootingProject & environment settingsAdvanced tracing techniquesData & privacyTroubleshooting guidesViewing & managing tracesFilter tracesQuery traces (SDK)Compare tracesShare or unshare a trace publiclyView server logs for a traceBulk export trace dataAutomationsSet up automation rulesConfigure webhook notifications for rulesFeedback & evaluationLog user feedback using the SDKSet up online evaluatorsMonitoring & alertingMonitor projects with dashboardsAlertsConfigure webhook notifications for alertsInsights (Beta)Data type referenceRun (span) data formatFeedback data formatTrace query syntaxOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationIntegrationsTrace with LangChain (Python and JS/TS)Get startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumOn this pageInstallationQuick start1. Configure your environment2. Log a trace3. View your traceTrace selectivelyLog to a specific projectStaticallyDynamicallyAdd metadata and tags to tracesCustomize run nameCustomize run IDAccess run (span) ID for LangChain invocationsEnsure all traces are submitted before exitingTrace without setting environment variablesDistributed tracing with LangChain (Python)Interoperability between LangChain (Python) and LangSmith SDKInteroperability between LangChain.JS and LangSmith SDKTracing LangChain objects inside traceable (JS only)Tracing LangChain child runs via traceable / RunTree API (JS only)Tracing setupIntegrationsTrace with LangChain')]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Why should I use tracing in LangChain?\"\n",
    "simple_rag_graph.invoke({\"question\": question}, config={\"metadata\": {\"foo\": \"bar\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing Context Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable, trace\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable\n",
    "def retrieve_documents(question: str):\n",
    "    documents = retriever.invoke(question)\n",
    "    return documents\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_openai` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    with trace(\n",
    "        name=\"Generate Response\",\n",
    "        run_type=\"chain\", \n",
    "        inputs={\"question\": question, \"formatted_docs\": formatted_docs},\n",
    "        metadata={\"foo\": \"bar\"},\n",
    "    ) as ls_trace:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": RAG_SYSTEM_PROMPT\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "            }\n",
    "        ]\n",
    "        response = call_openai(messages)\n",
    "        ls_trace.end(outputs={\"output\": response})\n",
    "    return response\n",
    "\n",
    "\"\"\"\n",
    "call_openai\n",
    "- Returns the chat completion output from OpenAI\n",
    "\"\"\"\n",
    "@traceable\n",
    "def call_openai(\n",
    "    messages: List[dict], model: str = MODEL_NAME, temperature: float = 0.0\n",
    ") -> str:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\"\"\"\n",
    "langsmith_rag\n",
    "- Calls `retrieve_documents` to fetch documents\n",
    "- Calls `generate_response` to generate a response based on the fetched documents\n",
    "- Returns the model response\n",
    "\"\"\"\n",
    "@traceable\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative methods of tracing in LangSmith include using OpenTelemetry for both automatic and manual instrumentation, tracing with external applications that are compatible with OpenTelemetry, and utilizing LangChain-specific tracing features. Users can also log custom LLM traces and retriever traces to gain insights into their applications. For specific setups, integrating with the LangSmith REST API or utilizing the Vercel AI SDK are additional options available.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are some alternative methods of tracing in LangSmith?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrap_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.wrappers import wrap_openai\n",
    "import openai\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Wrap the OpenAI Client\n",
    "openai_client = wrap_openai(openai.Client())\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    # TODO: We don't need to use @traceable on a nested function call anymore,\n",
    "    # wrap_openai takes care of this for us\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "    )\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag_with_wrap_openai(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping your OpenAI client allows for automatic logging of traces without needing to use decorators or modify function calls, making it simpler and more seamless. In contrast, using the @traceable decorator requires you to explicitly decorate functions to enable tracing. Both methods can be used together in the same application for enhanced trace logging.\n"
     ]
    }
   ],
   "source": [
    "question = \"How is tracing by wrapping my OpenAI client any different from using @traceable?\"\n",
    "ai_answer = langsmith_rag_with_wrap_openai(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapped OpenAI client accepts all the same langsmith_extra parameters as @traceable decorated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CN052gd1Hv4bq1pzYbD5n4v825DoC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='George Orwell\\'s novel \"1984,\" published in 1949, is a dystopian narrative set in a totalitarian state that uses extreme surveillance, propaganda, and repression to control its citizens. The story follows Winston Smith, a man living in Oceania, a superstate ruled by the Party under the leadership of Big Brother. The novel explores various underlying themes that remain relevant today.\\n\\n### Key Themes:\\n\\n1. **Totalitarianism**:\\n   The central theme of \"1984\" is the exploration of totalitarian regimes and their methods of control. The Party employs technology, psychological manipulation, and violent repression to maintain power, illustrating the dangers of a government that seeks absolute control over its citizens.\\n\\n2. **Surveillance and Privacy**:\\n   Orwell\\'s vision of a world under constant surveillance raises important questions about privacy, autonomy, and freedom. The ubiquitous telescreens monitor individuals\\' actions and conversations, reflecting contemporary concerns about governmental overreach and the impacts of technology on personal liberties.\\n\\n3. **Language and Thought Control**:\\n   The concept of \"Newspeak,\" a language designed to limit freedom of thought, exemplifies how manipulating language can control ideas. This theme emphasizes the connection between language and thought, suggesting that if a society can restrict language, it can restrict the thoughts and expressions of its people.\\n\\n4. **Reality and Truth**:\\n   The Party\\'s manipulation of information and history is a critical theme in \"1984.\" The concept of \"doublethink,\" the ability to accept contradictory beliefs, demonstrates how power can distort reality and truth. This raises important questions about objectivity, propaganda, and the nature of truth in society.\\n\\n5. **Resistance and Individuality**:\\n   Winston\\'s struggle against the oppressive regime reflects the theme of individuality and the human spirit\\'s desire for freedom. The novel depicts the challenges and consequences of personal rebellion in a repressive society and raises questions about the limits of resistance.\\n\\n6. **Psychological Manipulation**:\\n   The Party\\'s use of psychological tactics to break down resistance and enforce conformity highlights the power of fear, indoctrination, and loyalty to a regime. This theme explores the psychological mechanisms of power and control exercised over individuals.\\n\\n7. **The Nature of Power**:\\n   Orwell examines power not just as a means to an end but as an end in itself. The Party\\'s desire to maintain control for its own sake ultimately leads to a society devoid of freedom or genuine happiness.\\n\\n### Context and Influence:\\n\"1984\" was heavily influenced by Orwell\\'s experiences with totalitarianism, especially the rise of fascism and communism in the early to mid-20th century. It serves as a warning against the dangers of unregulated government power and the importance of safeguarding democratic values and individual freedoms. The novel\\'s insights into the human condition, the manipulation of truth, and the fragility of freedom continue to resonate in discussions about politics, society, and technology today.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1759597888, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=587, prompt_tokens=28, total_tokens=615, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the novel 1984 by George Orwell based on? What are its underyling themes?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    langsmith_extra={\"metadata\": {\"foo\": \"bar\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## [Advanced] RunTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"false\"\n",
    "\n",
    "from langsmith import utils\n",
    "utils.tracing_is_enabled() # not sure why it keeps returning true here, i've even explicitly declared it in the env file. will check on this further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have rewritten our RAG application, except this time we pass a RunTree argument through our function calls, and create child runs at each layer. This gives our RunTree the same hierarchy that we were automatically able to establish with @traceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import RunTree\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "load_dotenv(dotenv_path=\"E:/MAT496-LangSmith/.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(api_key=api_key)\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "def retrieve_documents(parent_run: RunTree, question: str):\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Retrieve Documents\",\n",
    "        run_type=\"retriever\",\n",
    "        inputs={\"question\": question},\n",
    "    )\n",
    "    documents = retriever.invoke(question)\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"documents\": documents})\n",
    "    child_run.post()\n",
    "    return documents\n",
    "\n",
    "def generate_response(parent_run: RunTree, question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    rag_system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    \"\"\"\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Generate Response\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question, \"documents\": documents},\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": rag_system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    openai_response = call_openai(child_run, messages)\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"openai_response\": openai_response})\n",
    "    child_run.post()\n",
    "    return openai_response\n",
    "\n",
    "def call_openai(\n",
    "    parent_run: RunTree, messages: List[dict], model: str = \"gpt-4o-mini\", temperature: float = 0.0\n",
    ") -> str:\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"OpenAI Call\",\n",
    "        run_type=\"llm\",\n",
    "        inputs={\"messages\": messages},\n",
    "    )\n",
    "    openai_response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"openai_response\": openai_response})\n",
    "    child_run.post()\n",
    "    return openai_response\n",
    "\n",
    "def langsmith_rag(question: str):\n",
    "    # Create a root RunTree\n",
    "    root_run_tree = RunTree(\n",
    "        name=\"Chat Pipeline\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question}\n",
    "    )\n",
    "\n",
    "    # Pass our RunTree into the nested function calls\n",
    "    documents = retrieve_documents(root_run_tree, question)\n",
    "    response = generate_response(root_run_tree, question, documents)\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    # Post our final output\n",
    "    root_run_tree.end(outputs={\"generation\": output})\n",
    "    root_run_tree.post()\n",
    "    return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with RunTree in LangSmith allows for more granular filtering and visualization of runs based on their hierarchical structure, which can enhance the understanding of complex workflows. Unlike other methods, RunTree focuses on the relationships between runs, making it easier to analyze specific sequences of operations. This can provide deeper insights into the performance and behavior of your application compared to standard tracing methods.\n"
     ]
    }
   ],
   "source": [
    "question = \"How is tracing with RunTree any different from all the other methods in LangSmith?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
